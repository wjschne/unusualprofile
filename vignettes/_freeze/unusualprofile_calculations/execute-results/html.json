{
  "hash": "ecf864cd33e497d5c14b2db63ba4da59",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Calculations performed by the unusualprofile package\"\nauthor: \"W. Joel Schneider & Feng Ji\"\ndate: \"2025-08-16\"\nformat: \n  html:\n    toc: true\n    html-math-method: mathjax\nbibliography: bibliography.bib\ncsl: apa.csl\nfont-import: https://fonts.googleapis.com/css?family=Titillium+ Web:100&amp;subset=latin-ext\nfont-family: 'Titillium Web'\nvignette: >\n  %\\VignetteIndexEntry{Vignette's Title}\n  %\\VignetteEngine{quarto::html}\n  %\\VignetteEncoding{UTF-8}\n---\n\n\n::: {.cell}\n<style type=\"text/css\">\n\n@import url('http://fonts.googleapis.com/css?family=Titillium+Web');\nbody {font-family: 'Titillium Web', 'Open Sans', 'sans-serif'; \n      font-size:18px; \n      line-height:1.25;}\n\n.caption {text-align:right; font-size:10pt}\ntable caption {text-align:left; font-size:10pt}\n\nimg {border: none}\n</style>\n:::\n\n\n\n\n\n::: {.cell}\n\n:::\n\n\n\n\n::: {.cell}\n\n:::\n\n\n\n::: {.cell}\n\n:::\n\n\n\n::: {.cell}\n\n:::\n\n\n\nSuppose that there are a set of variables $X$ that are related to each other as seen in @fig-onedimensional.\n\n:::{#fig-onedimensional}\n![](One_dimensional.svg){width=300}\n\nA simple model with standardized loadings\n\n:::\n\n\n\nSuppose that there is a profile of scores in $X$ such that:\n\n$$X=\\{X_1,X_2, X_3, X_4\\} = \\{2,3,1,2\\}. $$\n\n\n\nAs seen in @fig-example-profile, this profile of scores is summarized by a composite score of 2.30.\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Example profile in a standard multivariate normal distribution.](unusualprofile_calculations_files/figure-html/fig-example-profile-1.png){#fig-example-profile width=100% height=100%}\n:::\n:::\n\n\nHow can we calculate the Mahalanobis distance for profiles that all have the same elevation (i.e., composite score)? For your reference, we will do everything \"by hand\" using matrix algebra.\n\nIn r, we can make a named vector of scores like so:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nX <- c(\n  X_1 = 2,\n  X_2 = 3,\n  X_3 = 1,\n  X_4 = 2\n)\n\nX\n#> X_1 X_2 X_3 X_4 \n#>   2   3   1   2\n```\n:::\n\n\nWe will need to store variable names:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nv_observed <- names(X)\nv_latent <- \"X\"\nv_composite <- \"X_Composite\"\nv_names <- c(v_observed, v_composite)\n```\n:::\n\n\nWe can create a matrix of factor loadings:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlambda <- c(0.95, 0.90, 0.85, 0.60) %>%\n  matrix() %>%\n  `rownames<-`(v_observed) %>%\n  `colnames<-`(v_latent)\n\nlambda\n#>        X\n#> X_1 0.95\n#> X_2 0.90\n#> X_3 0.85\n#> X_4 0.60\n```\n:::\n\n\n\nNow we calculate the model-implied correlations among the observed variables:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Observed Correlations\nR_X <- lambda %*% t(lambda) %>%\n  `diag<-`(1)\n\nR_X\n#>        X_1   X_2    X_3  X_4\n#> X_1 1.0000 0.855 0.8075 0.57\n#> X_2 0.8550 1.000 0.7650 0.54\n#> X_3 0.8075 0.765 1.0000 0.51\n#> X_4 0.5700 0.540 0.5100 1.00\n```\n:::\n\n\nPresented formally, the model-implied correlations are:\n\n$$R_{X} \\approx \\begin{bmatrix}\n1 & .85 & .81 & .57\\\\\n.85 & 1 & .76 & .54\\\\\n.81 & .76 & 1 & .51\\\\\n.57 & .54 & .51 & 1\n\\end{bmatrix}$$\n\nWe need to use this matrix to create a new 5 × 5 correlation matrix that includes the correlations among the four variables and also each variable's correlation with the general composite score (i.e., the standardized sum of four variables). Fortunately, such a matrix can be calculated with only a few steps.\n\nWe will need a \"weight\" matrix that will select each variable individually and also the sum of the four variables.\n\n$$w=\\begin{bmatrix}\n1 & 0 & 0 & 0 & 1\\\\\n0 & 1 & 0 & 0 & 1\\\\\n0 & 0 & 1 & 0 & 1\\\\\n0 & 0 & 0 & 1 & 1\n\\end{bmatrix}$$\n\nNotice that the first column of this matrix has a 1 in first position and zeroes elsewhere. It selects the first variable, *X*~1~. The second column selects *X*~2~, and so on to the fourth column. The last column is all ones, which will select all four variables and add them up.\n\nWe can construct this matrix with the `diag` function, which creates an identity matrix. This matrix is appended to a column of ones:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nw <-  cbind(diag(4),\n            rep(1, 4)) %>%\n  `rownames<-`(v_observed) %>%\n  `colnames<-`(v_names)\nw\n#>     X_1 X_2 X_3 X_4 X_Composite\n#> X_1   1   0   0   0           1\n#> X_2   0   1   0   0           1\n#> X_3   0   0   1   0           1\n#> X_4   0   0   0   1           1\n```\n:::\n\n\nNow we can use the weight matrix *w* to calculate the covariance matrix:\n\n$$\\Sigma = w'R_{X}w$$\n\n\n\n$$\\Sigma \\approx \\begin{bmatrix}\n1 & .85 & .81 & .57 & 3.23\\\\\n.85 & 1 & .76 & .54 & 3.16\\\\\n.81 & .76 & 1 & .51 & 3.08\\\\\n.57 & .54 & .51 & 1 & 2.62\\\\\n3.23 & 3.16 & 3.08 & 2.62 & 12.09\n\\end{bmatrix}$$\n\n\n::: {.cell}\n\n```{.r .cell-code}\nSigma <- (t(w) %*% R_X %*% w)\nSigma\n#>                X_1   X_2    X_3  X_4 X_Composite\n#> X_1         1.0000 0.855 0.8075 0.57      3.2325\n#> X_2         0.8550 1.000 0.7650 0.54      3.1600\n#> X_3         0.8075 0.765 1.0000 0.51      3.0825\n#> X_4         0.5700 0.540 0.5100 1.00      2.6200\n#> X_Composite 3.2325 3.160 3.0825 2.62     12.0950\n```\n:::\n\n\n\n\n\nNow we need to convert the covariance matrix to a correlation matrix. With matrix equations, we would need to create a matrix of with a vector of variances on the diagonal:\n\n$$D = \\text{diag}(\\Sigma)$$ Then we would take the square root, invert this matrix, and then pre-multiply it and post-multiply it by the covariance matrix.\n\n$$R_{All} = D^{-0.5}\\Sigma D^{-0.5}$$\n\n$$R_{All} \\approx \\begin{bmatrix}\n1 & .86 & .81 & .57 & .93\\\\\n.86 & 1 & .76 & .54 & .91\\\\\n.81 & .76 & 1 & .51 & .89\\\\\n.57 & .54 & .51 & 1 & .75\\\\\n.93 & .91 & .89 & .75 & 1\n\\end{bmatrix}$$\n\n\nIf we really want to use pure matrix algebra functions, we could do this:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nD_root_inverted <- Sigma %>%\n  diag() %>%\n  sqrt() %>%\n  diag() %>%\n  solve() %>%\n  `rownames<-`(v_names) %>%\n  `colnames<-`(v_names)\n\nR_all <- D_root_inverted %*% Sigma %*% D_root_inverted\n\nR_all\n#>                   X_1       X_2       X_3       X_4 X_Composite\n#> X_1         1.0000000 0.8550000 0.8075000 0.5700000   0.9294705\n#> X_2         0.8550000 1.0000000 0.7650000 0.5400000   0.9086239\n#> X_3         0.8075000 0.7650000 1.0000000 0.5100000   0.8863396\n#> X_4         0.5700000 0.5400000 0.5100000 1.0000000   0.7533527\n#> X_Composite 0.9294705 0.9086239 0.8863396 0.7533527   1.0000000\n```\n:::\n\n\nHowever, it is probably best to sidestep all this complication of converting covariances to correlations with the `cov2cor` function:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Convert covariance matrix to correlations\nR_all <- cov2cor(Sigma)\n\nR_all\n#>                   X_1       X_2       X_3       X_4 X_Composite\n#> X_1         1.0000000 0.8550000 0.8075000 0.5700000   0.9294705\n#> X_2         0.8550000 1.0000000 0.7650000 0.5400000   0.9086239\n#> X_3         0.8075000 0.7650000 1.0000000 0.5100000   0.8863396\n#> X_4         0.5700000 0.5400000 0.5100000 1.0000000   0.7533527\n#> X_Composite 0.9294705 0.9086239 0.8863396 0.7533527   1.0000000\n```\n:::\n\n\n\n## Calculate composite scores\n\nTo calculate the standardized composite score $z_C$, add each variable's deviation from its own mean and divide by the square root of the sum of the observed score covariance matrix.\n\n$$z_C=\\frac{1'(X-\\mu_X)}{\\sqrt{1'\\Sigma_X1}}$$\n\nWhere\n\n> $z_C$ is a standardized composite score.\\\n> $X$ is a vector of observed scores.\\\n> $\\mu_X$ is the vector of means for the $X$ variables.\\\n> $\\Sigma_X$ is the covariance matrix of the $X$ variables.\\\n> $1$ is a vector of ones compatible with $\\Sigma_X$.\n\nThe composite score is:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Population means of observed variables\nmu_X <- rep_along(X, 0)\n\n# Population standard deviations of observed variables\nsd_X <- rep_along(X, 1)\n\n# Covariance Matrix\nSigma_X <- diag(sd_X) %*% R_X %*% diag(sd_X)\n\n# Vector of ones\nones <- rep_along(X, 1)\n\n# Standardized composite score\nz_C <- c(ones %*% (X - mu_X) / sqrt(ones %*% (Sigma_X) %*% ones))\n\n```\n:::\n\n\n## Estimate expected test scores conditioned on a composite score\n\nGiven a particular composite score, we need to calculate a predicted score. That is, if the composite score is 1.5 standard deviations above the mean, what are the expected subtest scores?\n\n$$\\hat{X}=\\sigma_Xz_Cr_{XX_C}+\\mu_X$$\n\nWhere\n\n> $\\hat{X}$ is the vector of expected subtest scores\\\n> $\\sigma_X$ is the vector of standard deviations for $X$\\\n> $z_C$ is the composite score\\\n> $r_{XX_C}$ is a vector of correlations of each variable in $X$ with the composite score $z_C$\\\n> $\\mu_X$ is the vector of means for $X$\\\n\nThus,\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Predicted value of X, given composite score\nX_hat <- sd_X * z_C * R_all[v_observed, v_composite] + mu_X\n```\n:::\n\n\n## Calculating the Conditional Mahalanobis Distance\n\n$$d_{M_C}=\\sqrt{\\left(X-\\hat{X}\\right)'\\Sigma_{X}^{-1}\\left(X-\\hat{X}\\right)}$$\n\nWhere\n\n> $d_{M_C}$ is the Conditional Mahalanobis Distance\\\n> $X$ is a vector of subtest scores\\\n> $\\hat{X}$ is the vector of expected subtest scores\\\n> $\\Sigma_{X}$ is the covariance matrix of the subtest scores\n\n\n::: {.cell}\n\n```{.r .cell-code}\nd_mc <- c(sqrt(t(X - X_hat) %*% solve(Sigma_X) %*% (X - X_hat)))\nd_mc\n#> [1] 2.9246\n```\n:::\n\n\nSuppose there are *k* outcome scores, and *j* composite scores used to calculate the expected scores $\\hat{X}$. If multivariate normality of the subtest scores can be assumed, then the Conditional Mahalanobis Distance squared has a *χ*^2^ distribution with *k* − *j* degrees of freedom.\n\n$$d_{M_C}^{2} \\sim\\chi^{2}(k-j)$$\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Number of observed variables\nk <- length(v_observed)\n\n# Number of composite variables\nj <- length(v_composite)\n\n# Cumulative distribution function\np <- pchisq(d_mc ^ 2, df = k - j)\np\n#> [1] 0.9641406\n```\n:::\n\n\nIf we can assume that the observed variables in *X* are multivariate normal, a profile of *X* = {2,3,1,2} is more unusual than 96% of profiles that also have a composite score of *z~C~* = 2.3.\n\n",
    "supporting": [
      "unusualprofile_calculations_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}